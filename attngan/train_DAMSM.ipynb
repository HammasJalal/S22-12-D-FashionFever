{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VQIIzcMHzYK"
   },
   "source": [
    "**COLAB SPECIFIC CODE:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0XesfWNaHzYM",
    "outputId": "627e20fe-5c0a-44db-b9f6-21308e344cbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.18.3)\n",
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.19.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.5 MB 29.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.6.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.1.2)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.11.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->scikit-image) (3.0.9)\n",
      "Installing collected packages: scikit-image\n",
      "  Attempting uninstall: scikit-image\n",
      "    Found existing installation: scikit-image 0.18.3\n",
      "    Uninstalling scikit-image-0.18.3:\n",
      "      Successfully uninstalled scikit-image-0.18.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Successfully installed scikit-image-0.19.3\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "\n",
    "!python -m pip install -U scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SHOoreUIIL_V"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/content/drive/MyDrive/FYP/attngan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNm_TmFVHzYN"
   },
   "source": [
    "**IMPORTS:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GlurBdmLHzYN"
   },
   "outputs": [],
   "source": [
    "from miscc.utils import mkdir_p\n",
    "from miscc.utils import build_super_images\n",
    "from miscc.losses import sent_loss, words_loss\n",
    "from miscc.config import cfg, cfg_from_file\n",
    "\n",
    "from dataset import prepare_data, TextDataset as TextFashionGenDataset\n",
    "\n",
    "from model import RNN_ENCODER, CNN_ENCODER\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pprint\n",
    "import datetime\n",
    "import dateutil.tz\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "\n",
    "UPDATE_INTERVAL = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Iq7jVNU8HzYO"
   },
   "outputs": [],
   "source": [
    "def build_models(dataset):\n",
    "    # build model ############################################################\n",
    "    text_encoder = RNN_ENCODER(dataset.n_words, nhidden=cfg.TEXT.EMBEDDING_DIM)\n",
    "    image_encoder = CNN_ENCODER(cfg.TEXT.EMBEDDING_DIM)\n",
    "    labels = Variable(torch.LongTensor(range(cfg.TRAIN.BATCH_SIZE)))\n",
    "    start_epoch = 0\n",
    "    if cfg.TRAIN.NET_E != \"\":\n",
    "        state_dict = torch.load(cfg.TRAIN.NET_E)\n",
    "        text_encoder.load_state_dict(state_dict)\n",
    "        print(\"Load \", cfg.TRAIN.NET_E)\n",
    "        #\n",
    "        name = cfg.TRAIN.NET_E.replace(\"text_encoder\", \"image_encoder\")\n",
    "        state_dict = torch.load(name)\n",
    "        image_encoder.load_state_dict(state_dict)\n",
    "        print(\"Load \", name)\n",
    "\n",
    "        istart = cfg.TRAIN.NET_E.rfind(\"_\") + 8\n",
    "        iend = cfg.TRAIN.NET_E.rfind(\".\")\n",
    "        start_epoch = cfg.TRAIN.NET_E[istart:iend]\n",
    "        start_epoch = int(start_epoch) + 1\n",
    "        print(\"start_epoch\", start_epoch)\n",
    "    if cfg.CUDA:\n",
    "        text_encoder = text_encoder.cuda()\n",
    "        image_encoder = image_encoder.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "    return text_encoder, image_encoder, labels, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "C6_8d1R_HzYO"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    dataloader,\n",
    "    cnn_model,\n",
    "    rnn_model,\n",
    "    batch_size,\n",
    "    labels,\n",
    "    optimizer,\n",
    "    epoch,\n",
    "    ixtoword,\n",
    "    image_dir,\n",
    "):\n",
    "    cnn_model.train()\n",
    "    rnn_model.train()\n",
    "    s_total_loss0 = 0\n",
    "    s_total_loss1 = 0\n",
    "    w_total_loss0 = 0\n",
    "    w_total_loss1 = 0\n",
    "    count = (epoch + 1) * len(dataloader)\n",
    "    start_time = time.time()\n",
    "\n",
    "    for step, data in enumerate(dataloader, 0):\n",
    "        # print('step', step)\n",
    "        rnn_model.zero_grad()\n",
    "        cnn_model.zero_grad()\n",
    "\n",
    "        imgs, captions, cap_lens, class_ids, keys = prepare_data(data)\n",
    "\n",
    "        # nef -- cfg.TEXT.EMBEDDING_DIM = 256 (for FashionGen)\n",
    "\n",
    "        # words_features: batch_size x nef x 17 x 17\n",
    "        # sent_code: batch_size x nef\n",
    "        words_features, sent_code = cnn_model(imgs[-1])\n",
    "        # --> batch_size x nef x 17*17\n",
    "        nef, att_sze = words_features.size(1), words_features.size(2)\n",
    "        # words_features = words_features.view(batch_size, nef, -1)\n",
    "\n",
    "        hidden = rnn_model.init_hidden(batch_size)\n",
    "        # words_emb: batch_size x nef x seq_len\n",
    "        # sent_emb: batch_size x nef\n",
    "        words_emb, sent_emb = rnn_model(captions, cap_lens, hidden)\n",
    "\n",
    "        w_loss0, w_loss1, attn_maps = words_loss(\n",
    "            words_features, words_emb, labels, cap_lens, class_ids, batch_size\n",
    "        )\n",
    "        w_total_loss0 += w_loss0.data\n",
    "        w_total_loss1 += w_loss1.data\n",
    "        loss = w_loss0 + w_loss1\n",
    "\n",
    "        s_loss0, s_loss1 = sent_loss(sent_code, sent_emb, labels, class_ids, batch_size)\n",
    "        loss += s_loss0 + s_loss1\n",
    "        s_total_loss0 += s_loss0.data\n",
    "        s_total_loss1 += s_loss1.data\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # `clip_grad_norm` helps prevent\n",
    "        # the exploding gradient problem in RNNs / LSTMs.\n",
    "        torch.nn.utils.clip_grad_norm_(rnn_model.parameters(), cfg.TRAIN.RNN_GRAD_CLIP)\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % UPDATE_INTERVAL == 0:\n",
    "            count = epoch * len(dataloader) + step\n",
    "\n",
    "            s_cur_loss0 = s_total_loss0.item() / UPDATE_INTERVAL\n",
    "            s_cur_loss1 = s_total_loss1.item() / UPDATE_INTERVAL\n",
    "\n",
    "            w_cur_loss0 = w_total_loss0.item() / UPDATE_INTERVAL\n",
    "            w_cur_loss1 = w_total_loss1.item() / UPDATE_INTERVAL\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            print(\n",
    "                \"| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | \"\n",
    "                \"s_loss {:5.2f} {:5.2f} | \"\n",
    "                \"w_loss {:5.2f} {:5.2f}\".format(\n",
    "                    epoch,\n",
    "                    step,\n",
    "                    len(dataloader),\n",
    "                    elapsed * 1000.0 / UPDATE_INTERVAL,\n",
    "                    s_cur_loss0,\n",
    "                    s_cur_loss1,\n",
    "                    w_cur_loss0,\n",
    "                    w_cur_loss1,\n",
    "                )\n",
    "            )\n",
    "            s_total_loss0 = 0\n",
    "            s_total_loss1 = 0\n",
    "            w_total_loss0 = 0\n",
    "            w_total_loss1 = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "            # attention Maps\n",
    "            img_set, _ = build_super_images(\n",
    "                imgs[-1].cpu(), captions, ixtoword, attn_maps, att_sze\n",
    "            )\n",
    "\n",
    "            if img_set is not None:\n",
    "                im = Image.fromarray(img_set)\n",
    "                fullpath = \"%s/attention_maps%d.png\" % (image_dir, step)\n",
    "                im.save(fullpath)\n",
    "\n",
    "    return count\n",
    "\n",
    "def evaluate(dataloader, cnn_model, rnn_model, batch_size, labels):\n",
    "    cnn_model.eval()\n",
    "    rnn_model.eval()\n",
    "    s_total_loss = 0\n",
    "    w_total_loss = 0\n",
    "\n",
    "    for step, data in enumerate(dataloader, 0):\n",
    "        real_imgs, captions, cap_lens, class_ids, keys = prepare_data(data)\n",
    "\n",
    "        words_features, sent_code = cnn_model(real_imgs[-1])\n",
    "        # nef = words_features.size(1)\n",
    "        # words_features = words_features.view(batch_size, nef, -1)\n",
    "\n",
    "        hidden = rnn_model.init_hidden(batch_size)\n",
    "        words_emb, sent_emb = rnn_model(captions, cap_lens, hidden)\n",
    "\n",
    "        w_loss0, w_loss1, attn = words_loss(\n",
    "            words_features, words_emb, labels, cap_lens, class_ids, batch_size\n",
    "        )\n",
    "        w_total_loss += (w_loss0 + w_loss1).data\n",
    "\n",
    "        s_loss0, s_loss1 = sent_loss(sent_code, sent_emb, labels, class_ids, batch_size)\n",
    "        s_total_loss += (s_loss0 + s_loss1).data\n",
    "\n",
    "        if step == 50:\n",
    "            break\n",
    "\n",
    "    s_cur_loss = s_total_loss.item() / step\n",
    "    w_cur_loss = w_total_loss.item() / step\n",
    "\n",
    "    return s_cur_loss, w_cur_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9DgPIzBdHzYR"
   },
   "outputs": [],
   "source": [
    "def init_DAMSM(cfgdirectory):\n",
    "    cfg_from_file(cfgdirectory)\n",
    "\n",
    "    cfg.GPU_ID = 0  # -1 if on cpu, not tested so might break\n",
    "\n",
    "    print(\"Using config:\")\n",
    "    pprint.pprint(cfg)\n",
    "\n",
    "    # seeds\n",
    "    manual_seed = None\n",
    "    if not cfg.TRAIN.FLAG:\n",
    "        manual_seed = 100\n",
    "    elif manual_seed is None:\n",
    "        manual_seed = random.randint(1, 10000)\n",
    "    random.seed(manual_seed)\n",
    "    np.random.seed(manual_seed)\n",
    "    torch.manual_seed(manual_seed)\n",
    "    if cfg.CUDA:\n",
    "        torch.cuda.manual_seed_all(manual_seed)\n",
    "\n",
    "    ##########################################################################\n",
    "    now = datetime.datetime.now(dateutil.tz.tzlocal())\n",
    "    timestamp = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "    output_dir = \"./drive/MyDrive/FYP/attngan/data/%s_%s_%s\" % (cfg.DATASET_NAME, cfg.CONFIG_NAME, timestamp,)\n",
    "\n",
    "    model_dir = os.path.join(output_dir, \"Model\")\n",
    "    image_dir = os.path.join(output_dir, \"Image\")\n",
    "    mkdir_p(model_dir)\n",
    "    mkdir_p(image_dir)\n",
    "\n",
    "    torch.cuda.set_device(cfg.GPU_ID)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    # Get data loader ##################################################\n",
    "    imsize = cfg.TREE.BASE_SIZE * (2 ** (cfg.TREE.BRANCH_NUM - 1))\n",
    "    batch_size = cfg.TRAIN.BATCH_SIZE\n",
    "\n",
    "    # dataset images transforms\n",
    "\n",
    "    image_transform = transforms.Compose(\n",
    "        [transforms.Resize(imsize), transforms.RandomHorizontalFlip()]\n",
    "    )\n",
    "\n",
    "    # train data\n",
    "    dataset = TextFashionGenDataset(\n",
    "        cfg.DATA_DIR, \"train\", base_size=cfg.TREE.BASE_SIZE, transform=image_transform,\n",
    "    )\n",
    "\n",
    "    # print(dataset.n_words, dataset.embeddings_num)\n",
    "    assert dataset\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "        num_workers=int(cfg.WORKERS),\n",
    "    )\n",
    "\n",
    "    # # validation data #\n",
    "\n",
    "    dataset_val = TextFashionGenDataset(\n",
    "        cfg.DATA_DIR, \"test\", base_size=cfg.TREE.BASE_SIZE, transform=image_transform,\n",
    "    )\n",
    "\n",
    "    dataloader_val = torch.utils.data.DataLoader(\n",
    "        dataset_val,\n",
    "        batch_size=batch_size,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "        num_workers=int(cfg.WORKERS),\n",
    "    )\n",
    "\n",
    "    # Train ##############################################################\n",
    "    text_encoder, image_encoder, labels, start_epoch = build_models(dataset)\n",
    "\n",
    "    para = list(text_encoder.parameters())\n",
    "    for v in image_encoder.parameters():\n",
    "        if v.requires_grad:\n",
    "            para.append(v)\n",
    "    # optimizer = optim.Adam(para, lr=cfg.TRAIN.ENCODER_LR, betas=(0.5, 0.999))\n",
    "    # At any point you can hit Ctrl + C to break out of training early.\n",
    "    try:\n",
    "        lr = cfg.TRAIN.ENCODER_LR\n",
    "        for epoch in range(start_epoch, cfg.TRAIN.MAX_EPOCH):\n",
    "            optimizer = optim.Adam(para, lr=lr, betas=(0.5, 0.999))\n",
    "            epoch_start_time = time.time()\n",
    "\n",
    "            count = train(\n",
    "                dataloader,\n",
    "                image_encoder,\n",
    "                text_encoder,\n",
    "                batch_size,\n",
    "                labels,\n",
    "                optimizer,\n",
    "                epoch,\n",
    "                dataset.ixtoword,\n",
    "                image_dir,\n",
    "            )\n",
    "\n",
    "            print(\"-\" * 89)\n",
    "            if len(dataloader_val) > 0:\n",
    "                s_loss, w_loss = evaluate(\n",
    "                    dataloader_val, image_encoder, text_encoder, batch_size, labels\n",
    "                )\n",
    "                print(\n",
    "                    \"| end epoch {:3d} | valid loss \"\n",
    "                    \"{:5.2f} {:5.2f} | lr {:.5f}|\".format(epoch, s_loss, w_loss, lr)\n",
    "                )\n",
    "            print(\"-\" * 89)\n",
    "            if lr > cfg.TRAIN.ENCODER_LR / 10.0:\n",
    "                lr *= 0.98\n",
    "\n",
    "            if epoch % cfg.TRAIN.SNAPSHOT_INTERVAL == 0 or epoch == cfg.TRAIN.MAX_EPOCH:\n",
    "                torch.save(\n",
    "                    image_encoder.state_dict(),\n",
    "                    \"%s/image_encoder%d.pth\" % (model_dir, epoch),\n",
    "                )\n",
    "                torch.save(\n",
    "                    text_encoder.state_dict(),\n",
    "                    \"%s/text_encoder%d.pth\" % (model_dir, epoch),\n",
    "                )\n",
    "                print(\"Save G/Ds models.\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"-\" * 89)\n",
    "        print(\"Exiting from training early\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "f74128d6505444ef902f9ef184470d2e",
      "19ccb99508c4460ca080e7f7a9de65a3",
      "a7ddb5dd50fc459aaff3c11d459d9494",
      "37b447345a3d47ae8c48b79a5520464c",
      "62b052ba028f47a483388c8eadbf880a",
      "b24b62ae7fc9407980936b249bf8c761",
      "f98a6a33bf3b4713b24371f40b34cea7",
      "4762ef4d593b4a3a8bc446907aab5cce",
      "d920f8a659f04f9b991472e956ca0a7a",
      "c3cf980f9342482d9fd44165f6f09402",
      "426a051ac83243f09297a742591da9bd"
     ]
    },
    "id": "RUdmZ-A9-KJf",
    "outputId": "0283bdb3-b10a-4ae2-85c6-961d5ca1378b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config:\n",
      "{'B_VALIDATION': False,\n",
      " 'CONFIG_NAME': 'DAMSM',\n",
      " 'CUDA': True,\n",
      " 'DATASET_NAME': 'fashiongen2',\n",
      " 'DATA_DIR': './data/fashiongen',\n",
      " 'GAN': {'B_ATTENTION': True,\n",
      "         'B_DCGAN': False,\n",
      "         'CONDITION_DIM': 100,\n",
      "         'DF_DIM': 64,\n",
      "         'GF_DIM': 128,\n",
      "         'R_NUM': 2,\n",
      "         'Z_DIM': 100},\n",
      " 'GPU_ID': 0,\n",
      " 'RNN_TYPE': 'LSTM',\n",
      " 'TEXT': {'CAPTIONS_PER_IMAGE': 1, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 10},\n",
      " 'TRAIN': {'BATCH_SIZE': 32,\n",
      "           'B_NET_D': True,\n",
      "           'DISCRIMINATOR_LR': 0.0002,\n",
      "           'ENCODER_LR': 0.001,\n",
      "           'FLAG': True,\n",
      "           'GENERATOR_LR': 0.0002,\n",
      "           'MAX_EPOCH': 401,\n",
      "           'NET_E': '/home/jupyter/temp/attngan/drive/MyDrive/FYP/attngan/data/fashiongen2_DAMSM_2022_06_30_03_57_51/Model/text_encoder132.pth',\n",
      "           'NET_G': '',\n",
      "           'RNN_GRAD_CLIP': 0.25,\n",
      "           'SMOOTH': {'GAMMA1': 4.0,\n",
      "                      'GAMMA2': 5.0,\n",
      "                      'GAMMA3': 10.0,\n",
      "                      'LAMBDA': 1.0},\n",
      "           'SNAPSHOT_INTERVAL': 2},\n",
      " 'TREE': {'BASE_SIZE': 299, 'BRANCH_NUM': 1},\n",
      " 'WORKERS': 2}\n",
      "Load from:  ./data/fashiongen/captions2_attngan.pickle\n",
      "Load from:  ./data/fashiongen/captions2_attngan.pickle\n",
      "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
      "Load  /home/jupyter/temp/attngan/drive/MyDrive/FYP/attngan/data/fashiongen2_DAMSM_2022_06_30_03_57_51/Model/text_encoder132.pth\n",
      "Load  /home/jupyter/temp/attngan/drive/MyDrive/FYP/attngan/data/fashiongen2_DAMSM_2022_06_30_03_57_51/Model/image_encoder132.pth\n",
      "start_epoch 133\n",
      "| epoch 133 |     0/  445 batches | ms/batch  3.45 | s_loss  0.00  0.00 | w_loss  0.00  0.00\n",
      "| epoch 133 |   200/  445 batches | ms/batch 252.57 | s_loss  0.71  0.74 | w_loss  0.27  0.31\n",
      "-----------------------------------------------------------------------------------------\n",
      "Exiting from training early\n"
     ]
    }
   ],
   "source": [
    "init_DAMSM(\"./cfg/DAMSM/fashiongen2.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "47c57751f176447e90cc0785d1b772de",
      "956467b8294d4eb9921812a90ecfbb85",
      "1e9338afcd3e42329a6f867dada96632",
      "c42b4aa4456446baac1bccb602746003",
      "1c5b313dc1bf47e4ad64b87f5d821575",
      "f740b5c24e694ff2b72e5f2c0681146d",
      "7edc393191e24b82a8f24fdce2582d15",
      "6494ba7d9d6e4c69aaa20dd0a8584a59",
      "9f27f12d2d9f44558060be6a7706e20d",
      "c39f44ca04ed449a89f9444d70b218f3",
      "fe8d451f12b54e5c9acfd8a6c4de5fcb"
     ]
    },
    "id": "0tl1Xp-oHzYT",
    "outputId": "ab98df6d-c7c0-4312-a87c-ea1d56996b94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using config:\n",
      "{'B_VALIDATION': False,\n",
      " 'CONFIG_NAME': 'DAMSM',\n",
      " 'CUDA': True,\n",
      " 'DATASET_NAME': 'fashiongen2',\n",
      " 'DATA_DIR': './drive/MyDrive/FYP/attngan/data/fashiongen',\n",
      " 'GAN': {'B_ATTENTION': True,\n",
      "         'B_DCGAN': False,\n",
      "         'CONDITION_DIM': 100,\n",
      "         'DF_DIM': 64,\n",
      "         'GF_DIM': 128,\n",
      "         'R_NUM': 2,\n",
      "         'Z_DIM': 100},\n",
      " 'GPU_ID': 0,\n",
      " 'RNN_TYPE': 'LSTM',\n",
      " 'TEXT': {'CAPTIONS_PER_IMAGE': 1, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 10},\n",
      " 'TRAIN': {'BATCH_SIZE': 32,\n",
      "           'B_NET_D': True,\n",
      "           'DISCRIMINATOR_LR': 0.0002,\n",
      "           'ENCODER_LR': 0.001,\n",
      "           'FLAG': True,\n",
      "           'GENERATOR_LR': 0.0002,\n",
      "           'MAX_EPOCH': 401,\n",
      "           'NET_E': '',\n",
      "           'NET_G': '',\n",
      "           'RNN_GRAD_CLIP': 0.25,\n",
      "           'SMOOTH': {'GAMMA1': 4.0,\n",
      "                      'GAMMA2': 5.0,\n",
      "                      'GAMMA3': 10.0,\n",
      "                      'LAMBDA': 1.0},\n",
      "           'SNAPSHOT_INTERVAL': 2},\n",
      " 'TREE': {'BASE_SIZE': 299, 'BRANCH_NUM': 1},\n",
      " 'WORKERS': 2}\n",
      "Load from:  ./drive/MyDrive/FYP/attngan/data/fashiongen/captions2_attngan.pickle\n",
      "Load from:  ./drive/MyDrive/FYP/attngan/data/fashiongen/captions2_attngan.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/inception.py:48: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.\n",
      "  FutureWarning,\n",
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c57751f176447e90cc0785d1b772de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/104M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/FYP/attngan/miscc/losses.py:125: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/cuda/Indexing.cu:967.)\n",
      "  similarities.data.masked_fill_(masks, -float('inf'))\n",
      "/content/drive/MyDrive/FYP/attngan/miscc/losses.py:52: UserWarning: masked_fill_ received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/cuda/Indexing.cu:967.)\n",
      "  scores0.data.masked_fill_(masks, -float('inf'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 |     0/  445 batches | ms/batch 31.65 | s_loss  0.02  0.02 | w_loss  0.02  0.02\n",
      "| epoch   0 |   200/  445 batches | ms/batch 496.13 | s_loss  2.71  2.75 | w_loss  2.80  2.68\n",
      "| epoch   0 |   400/  445 batches | ms/batch 349.77 | s_loss  2.32  2.35 | w_loss  2.10  2.13\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   0 | valid loss  4.72  4.24 | lr 0.00100|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch   1 |     0/  445 batches | ms/batch  4.91 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch   1 |   200/  445 batches | ms/batch 345.23 | s_loss  2.11  2.16 | w_loss  1.85  1.88\n",
      "| epoch   1 |   400/  445 batches | ms/batch 327.68 | s_loss  2.05  2.09 | w_loss  1.77  1.82\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   1 | valid loss  4.64  4.06 | lr 0.00098|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |     0/  445 batches | ms/batch  4.71 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch   2 |   200/  445 batches | ms/batch 330.65 | s_loss  1.91  1.95 | w_loss  1.62  1.67\n",
      "| epoch   2 |   400/  445 batches | ms/batch 334.28 | s_loss  1.92  1.96 | w_loss  1.62  1.66\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   2 | valid loss  4.44  3.88 | lr 0.00096|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch   3 |     0/  445 batches | ms/batch  4.60 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch   3 |   200/  445 batches | ms/batch 332.46 | s_loss  1.79  1.82 | w_loss  1.47  1.50\n",
      "| epoch   3 |   400/  445 batches | ms/batch 325.76 | s_loss  1.79  1.83 | w_loss  1.45  1.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   3 | valid loss  4.34  3.84 | lr 0.00094|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |     0/  445 batches | ms/batch  4.42 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch   4 |   200/  445 batches | ms/batch 339.43 | s_loss  1.72  1.76 | w_loss  1.38  1.43\n",
      "| epoch   4 |   400/  445 batches | ms/batch 327.88 | s_loss  1.71  1.76 | w_loss  1.37  1.41\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   4 | valid loss  4.32  3.80 | lr 0.00092|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch   5 |     0/  445 batches | ms/batch  4.76 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch   5 |   200/  445 batches | ms/batch 336.59 | s_loss  1.60  1.64 | w_loss  1.27  1.31\n",
      "| epoch   5 |   400/  445 batches | ms/batch 327.30 | s_loss  1.63  1.68 | w_loss  1.29  1.33\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   5 | valid loss  4.38  3.78 | lr 0.00090|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |     0/  445 batches | ms/batch  4.74 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch   6 |   200/  445 batches | ms/batch 330.76 | s_loss  1.56  1.60 | w_loss  1.21  1.26\n",
      "| epoch   6 |   400/  445 batches | ms/batch 334.36 | s_loss  1.57  1.62 | w_loss  1.21  1.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   6 | valid loss  4.42  3.94 | lr 0.00089|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch   7 |     0/  445 batches | ms/batch  4.41 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch   7 |   200/  445 batches | ms/batch 330.79 | s_loss  1.50  1.55 | w_loss  1.15  1.20\n",
      "| epoch   7 |   400/  445 batches | ms/batch 327.70 | s_loss  1.50  1.55 | w_loss  1.14  1.18\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   7 | valid loss  4.33  3.80 | lr 0.00087|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |     0/  445 batches | ms/batch  4.85 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch   8 |   200/  445 batches | ms/batch 331.37 | s_loss  1.46  1.51 | w_loss  1.11  1.14\n",
      "| epoch   8 |   400/  445 batches | ms/batch 327.67 | s_loss  1.47  1.53 | w_loss  1.11  1.16\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   8 | valid loss  4.34  3.86 | lr 0.00085|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch   9 |     0/  445 batches | ms/batch  4.61 | s_loss  0.01  0.01 | w_loss  0.00  0.01\n",
      "| epoch   9 |   200/  445 batches | ms/batch 339.77 | s_loss  1.40  1.45 | w_loss  1.02  1.07\n",
      "| epoch   9 |   400/  445 batches | ms/batch 326.85 | s_loss  1.43  1.47 | w_loss  1.05  1.09\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch   9 | valid loss  4.31  3.96 | lr 0.00083|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |     0/  445 batches | ms/batch  4.71 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  10 |   200/  445 batches | ms/batch 331.34 | s_loss  1.37  1.41 | w_loss  0.99  1.03\n",
      "| epoch  10 |   400/  445 batches | ms/batch 324.75 | s_loss  1.39  1.43 | w_loss  1.00  1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  10 | valid loss  4.30  3.91 | lr 0.00082|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  11 |     0/  445 batches | ms/batch  4.75 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  11 |   200/  445 batches | ms/batch 330.32 | s_loss  1.33  1.37 | w_loss  0.96  1.00\n",
      "| epoch  11 |   400/  445 batches | ms/batch 327.02 | s_loss  1.37  1.41 | w_loss  0.98  1.01\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  11 | valid loss  4.25  3.87 | lr 0.00080|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |     0/  445 batches | ms/batch  4.32 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  12 |   200/  445 batches | ms/batch 337.42 | s_loss  1.32  1.36 | w_loss  0.93  0.97\n",
      "| epoch  12 |   400/  445 batches | ms/batch 329.01 | s_loss  1.34  1.39 | w_loss  0.94  0.99\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  12 | valid loss  4.25  3.95 | lr 0.00078|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  13 |     0/  445 batches | ms/batch  5.03 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  13 |   200/  445 batches | ms/batch 332.43 | s_loss  1.27  1.32 | w_loss  0.86  0.91\n",
      "| epoch  13 |   400/  445 batches | ms/batch 334.88 | s_loss  1.29  1.34 | w_loss  0.91  0.94\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  13 | valid loss  4.31  3.99 | lr 0.00077|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |     0/  445 batches | ms/batch  4.62 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  14 |   200/  445 batches | ms/batch 328.88 | s_loss  1.24  1.29 | w_loss  0.84  0.89\n",
      "| epoch  14 |   400/  445 batches | ms/batch 324.77 | s_loss  1.26  1.31 | w_loss  0.86  0.91\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  14 | valid loss  4.26  3.98 | lr 0.00075|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  15 |     0/  445 batches | ms/batch  4.76 | s_loss  0.01  0.01 | w_loss  0.01  0.01\n",
      "| epoch  15 |   200/  445 batches | ms/batch 332.40 | s_loss  1.21  1.25 | w_loss  0.80  0.84\n",
      "| epoch  15 |   400/  445 batches | ms/batch 326.84 | s_loss  1.27  1.32 | w_loss  0.85  0.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  15 | valid loss  4.39  4.14 | lr 0.00074|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |     0/  445 batches | ms/batch  4.53 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  16 |   200/  445 batches | ms/batch 338.71 | s_loss  1.19  1.23 | w_loss  0.78  0.83\n",
      "| epoch  16 |   400/  445 batches | ms/batch 333.38 | s_loss  1.24  1.28 | w_loss  0.81  0.86\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  16 | valid loss  4.37  4.05 | lr 0.00072|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  17 |     0/  445 batches | ms/batch  4.46 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  17 |   200/  445 batches | ms/batch 331.79 | s_loss  1.17  1.21 | w_loss  0.76  0.80\n",
      "| epoch  17 |   400/  445 batches | ms/batch 335.72 | s_loss  1.23  1.28 | w_loss  0.80  0.85\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  17 | valid loss  4.34  3.96 | lr 0.00071|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |     0/  445 batches | ms/batch  4.33 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  18 |   200/  445 batches | ms/batch 331.01 | s_loss  1.17  1.22 | w_loss  0.76  0.81\n",
      "| epoch  18 |   400/  445 batches | ms/batch 327.12 | s_loss  1.16  1.20 | w_loss  0.75  0.79\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  18 | valid loss  4.37  4.30 | lr 0.00070|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  19 |     0/  445 batches | ms/batch  4.58 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  19 |   200/  445 batches | ms/batch 337.78 | s_loss  1.17  1.21 | w_loss  0.73  0.78\n",
      "| epoch  19 |   400/  445 batches | ms/batch 325.13 | s_loss  1.16  1.20 | w_loss  0.73  0.78\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  19 | valid loss  4.39  4.14 | lr 0.00068|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |     0/  445 batches | ms/batch  4.59 | s_loss  0.00  0.00 | w_loss  0.00  0.00\n",
      "| epoch  20 |   200/  445 batches | ms/batch 331.64 | s_loss  1.12  1.16 | w_loss  0.68  0.74\n",
      "| epoch  20 |   400/  445 batches | ms/batch 334.04 | s_loss  1.15  1.19 | w_loss  0.72  0.76\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  20 | valid loss  4.29  4.14 | lr 0.00067|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  21 |     0/  445 batches | ms/batch  4.79 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  21 |   200/  445 batches | ms/batch 331.02 | s_loss  1.10  1.15 | w_loss  0.69  0.74\n",
      "| epoch  21 |   400/  445 batches | ms/batch 325.40 | s_loss  1.13  1.17 | w_loss  0.69  0.74\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  21 | valid loss  4.36  4.30 | lr 0.00065|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  22 |     0/  445 batches | ms/batch  4.60 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  22 |   200/  445 batches | ms/batch 333.05 | s_loss  1.08  1.12 | w_loss  0.65  0.70\n",
      "| epoch  22 |   400/  445 batches | ms/batch 323.91 | s_loss  1.12  1.16 | w_loss  0.68  0.72\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  22 | valid loss  4.34  4.26 | lr 0.00064|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  23 |     0/  445 batches | ms/batch  4.40 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  23 |   200/  445 batches | ms/batch 339.83 | s_loss  1.07  1.12 | w_loss  0.64  0.69\n",
      "| epoch  23 |   400/  445 batches | ms/batch 325.67 | s_loss  1.11  1.15 | w_loss  0.68  0.75\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  23 | valid loss  4.41  4.31 | lr 0.00063|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  24 |     0/  445 batches | ms/batch  4.54 | s_loss  0.00  0.00 | w_loss  0.00  0.00\n",
      "| epoch  24 |   200/  445 batches | ms/batch 332.65 | s_loss  1.09  1.13 | w_loss  0.64  0.70\n",
      "| epoch  24 |   400/  445 batches | ms/batch 334.39 | s_loss  1.08  1.12 | w_loss  0.64  0.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  24 | valid loss  4.32  4.24 | lr 0.00062|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  25 |     0/  445 batches | ms/batch  4.67 | s_loss  0.00  0.00 | w_loss  0.00  0.00\n",
      "| epoch  25 |   200/  445 batches | ms/batch 332.30 | s_loss  1.05  1.09 | w_loss  0.61  0.66\n",
      "| epoch  25 |   400/  445 batches | ms/batch 332.25 | s_loss  1.08  1.12 | w_loss  0.62  0.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  25 | valid loss  4.35  4.21 | lr 0.00060|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  26 |     0/  445 batches | ms/batch  4.99 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  26 |   200/  445 batches | ms/batch 354.94 | s_loss  1.04  1.08 | w_loss  0.58  0.63\n",
      "| epoch  26 |   400/  445 batches | ms/batch 342.31 | s_loss  1.06  1.10 | w_loss  0.63  0.66\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  26 | valid loss  4.33  4.25 | lr 0.00059|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  27 |     0/  445 batches | ms/batch  5.28 | s_loss  0.00  0.00 | w_loss  0.00  0.00\n",
      "| epoch  27 |   200/  445 batches | ms/batch 365.95 | s_loss  1.00  1.05 | w_loss  0.55  0.61\n",
      "| epoch  27 |   400/  445 batches | ms/batch 340.62 | s_loss  1.07  1.11 | w_loss  0.61  0.68\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  27 | valid loss  4.30  4.14 | lr 0.00058|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  28 |     0/  445 batches | ms/batch  4.77 | s_loss  0.00  0.01 | w_loss  0.00  0.00\n",
      "| epoch  28 |   200/  445 batches | ms/batch 341.23 | s_loss  1.01  1.05 | w_loss  0.57  0.63\n",
      "| epoch  28 |   400/  445 batches | ms/batch 346.41 | s_loss  1.04  1.09 | w_loss  0.58  0.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  28 | valid loss  4.37  4.32 | lr 0.00057|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  29 |     0/  445 batches | ms/batch  4.72 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  29 |   200/  445 batches | ms/batch 332.57 | s_loss  1.00  1.04 | w_loss  0.56  0.61\n",
      "| epoch  29 |   400/  445 batches | ms/batch 336.20 | s_loss  1.03  1.08 | w_loss  0.58  0.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  29 | valid loss  4.34  4.27 | lr 0.00056|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  30 |     0/  445 batches | ms/batch  4.68 | s_loss  0.01  0.01 | w_loss  0.00  0.00\n",
      "| epoch  30 |   200/  445 batches | ms/batch 336.54 | s_loss  0.98  1.02 | w_loss  0.53  0.58\n",
      "| epoch  30 |   400/  445 batches | ms/batch 325.80 | s_loss  1.02  1.06 | w_loss  0.58  0.63\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  30 | valid loss  4.35  4.24 | lr 0.00055|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  31 |     0/  445 batches | ms/batch  4.62 | s_loss  0.00  0.00 | w_loss  0.00  0.00\n",
      "| epoch  31 |   200/  445 batches | ms/batch 338.64 | s_loss  0.99  1.03 | w_loss  0.54  0.59\n",
      "| epoch  31 |   400/  445 batches | ms/batch 326.46 | s_loss  1.01  1.05 | w_loss  0.56  0.61\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  31 | valid loss  4.38  4.19 | lr 0.00053|\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  32 |     0/  445 batches | ms/batch  4.32 | s_loss  0.00  0.00 | w_loss  0.00  0.00\n",
      "| epoch  32 |   200/  445 batches | ms/batch 339.76 | s_loss  0.99  1.03 | w_loss  0.52  0.57\n",
      "| epoch  32 |   400/  445 batches | ms/batch 328.19 | s_loss  0.99  1.03 | w_loss  0.54  0.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end epoch  32 | valid loss  4.39  4.30 | lr 0.00052|\n",
      "-----------------------------------------------------------------------------------------\n",
      "Save G/Ds models.\n",
      "| epoch  33 |     0/  445 batches | ms/batch  4.52 | s_loss  0.00  0.00 | w_loss  0.00  0.00\n",
      "-----------------------------------------------------------------------------------------\n",
      "Exiting from training early\n"
     ]
    }
   ],
   "source": [
    "init_DAMSM(\"/content/drive/MyDrive/FYP/attngan/cfg/DAMSM/fashiongen2.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDjpCpHoHzYT"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_DAMSM.ipynb",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m93"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c7402a058084e006ac4afd901fa4ad1abf73d2c6b9ce310bf6f2d235fd98e13"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "19ccb99508c4460ca080e7f7a9de65a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b24b62ae7fc9407980936b249bf8c761",
      "placeholder": "​",
      "style": "IPY_MODEL_f98a6a33bf3b4713b24371f40b34cea7",
      "value": "100%"
     }
    },
    "1c5b313dc1bf47e4ad64b87f5d821575": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e9338afcd3e42329a6f867dada96632": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6494ba7d9d6e4c69aaa20dd0a8584a59",
      "max": 108857766,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f27f12d2d9f44558060be6a7706e20d",
      "value": 108857766
     }
    },
    "37b447345a3d47ae8c48b79a5520464c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3cf980f9342482d9fd44165f6f09402",
      "placeholder": "​",
      "style": "IPY_MODEL_426a051ac83243f09297a742591da9bd",
      "value": " 104M/104M [00:01&lt;00:00, 65.7MB/s]"
     }
    },
    "426a051ac83243f09297a742591da9bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4762ef4d593b4a3a8bc446907aab5cce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47c57751f176447e90cc0785d1b772de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_956467b8294d4eb9921812a90ecfbb85",
       "IPY_MODEL_1e9338afcd3e42329a6f867dada96632",
       "IPY_MODEL_c42b4aa4456446baac1bccb602746003"
      ],
      "layout": "IPY_MODEL_1c5b313dc1bf47e4ad64b87f5d821575"
     }
    },
    "62b052ba028f47a483388c8eadbf880a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6494ba7d9d6e4c69aaa20dd0a8584a59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7edc393191e24b82a8f24fdce2582d15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "956467b8294d4eb9921812a90ecfbb85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f740b5c24e694ff2b72e5f2c0681146d",
      "placeholder": "​",
      "style": "IPY_MODEL_7edc393191e24b82a8f24fdce2582d15",
      "value": "100%"
     }
    },
    "9f27f12d2d9f44558060be6a7706e20d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a7ddb5dd50fc459aaff3c11d459d9494": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4762ef4d593b4a3a8bc446907aab5cce",
      "max": 108857766,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d920f8a659f04f9b991472e956ca0a7a",
      "value": 108857766
     }
    },
    "b24b62ae7fc9407980936b249bf8c761": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c39f44ca04ed449a89f9444d70b218f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3cf980f9342482d9fd44165f6f09402": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c42b4aa4456446baac1bccb602746003": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c39f44ca04ed449a89f9444d70b218f3",
      "placeholder": "​",
      "style": "IPY_MODEL_fe8d451f12b54e5c9acfd8a6c4de5fcb",
      "value": " 104M/104M [00:00&lt;00:00, 156MB/s]"
     }
    },
    "d920f8a659f04f9b991472e956ca0a7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f740b5c24e694ff2b72e5f2c0681146d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f74128d6505444ef902f9ef184470d2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_19ccb99508c4460ca080e7f7a9de65a3",
       "IPY_MODEL_a7ddb5dd50fc459aaff3c11d459d9494",
       "IPY_MODEL_37b447345a3d47ae8c48b79a5520464c"
      ],
      "layout": "IPY_MODEL_62b052ba028f47a483388c8eadbf880a"
     }
    },
    "f98a6a33bf3b4713b24371f40b34cea7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe8d451f12b54e5c9acfd8a6c4de5fcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
